{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 3: Procesamiento de vídeos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Librerías:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1: Implementación de un detector de movimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el video 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('video1.mkv')\n",
    "ret, pframe = cap.read()\n",
    "(h, w, c) = pframe.shape\n",
    "thr = 20\n",
    "writer = cv2.VideoWriter('video1_movement.mkv', cv2.VideoWriter_fourcc(*\"XVID\"),30, (w, h))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "        res = cv2.absdiff(frame, pframe)  #Calculamos la diferencia con respecto al frame anterior\n",
    "        res = cv2.cvtColor(res, cv2.COLOR_BGR2GRAY) #Pasamos a escala de grises\n",
    "        \n",
    "        aux = np.zeros((h,w))\n",
    "        for i in range(h):\n",
    "            for j in range(w):  #Por cada posición calculamos el promedio de su vecindad (3x3), incluido los bordes.\n",
    "                aux[i,j] = np.mean([res[x,y] for x in range(i-1,i+2) for y in range(j-1, j+2) if (x >= 0 and x < h and y >= 0 and y < w)])\n",
    "                \n",
    "        \n",
    "        res = np.array(aux > thr, dtype='uint8')*255  #Umbralizamos\n",
    "        res = np.broadcast_to(res[:,:,np.newaxis], (h, w, c)) #Broadcast a 3 canales\n",
    "        writer.write(res)\n",
    "        pframe = frame\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "writer.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el video 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('video2.mkv')\n",
    "ret, pframe = cap.read()\n",
    "(h, w, c) = pframe.shape\n",
    "thr = 20\n",
    "writer = cv2.VideoWriter('video2_movement.mkv', cv2.VideoWriter_fourcc(*\"XVID\"),30, (w, h))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "        res = cv2.absdiff(frame, pframe) #Calculamos la diferencia con respecto al frame anterior\n",
    "        res = cv2.cvtColor(res, cv2.COLOR_BGR2GRAY) #Pasamos a escala de grises\n",
    "        \n",
    "        aux = np.zeros((h,w))\n",
    "        for i in range(h):\n",
    "            for j in range(w): #Por cada posición calculamos el promedio de su vecindad (3x3), incluido los bordes.\n",
    "                aux[i,j] = np.mean([res[x,y] for x in range(i-1,i+2) for y in range(j-1, j+2) if (x >= 0 and x < h and y >= 0 and y < w)])\n",
    "                \n",
    "        \n",
    "        res = np.array(aux > thr, dtype='uint8')*255 #Umbralizamos\n",
    "        res = np.broadcast_to(res[:,:,np.newaxis], (h, w, c)) #Broadcast a 3 canales\n",
    "        writer.write(res)\n",
    "        pframe = frame\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "writer.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2: Implementación de un segmentador de escenas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el video 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('video1.mkv')\n",
    "ret, frame = cap.read()\n",
    "(h, w, c) = frame.shape\n",
    "font = cv2.FONT_HERSHEY_TRIPLEX\n",
    "white = (255,255,255)\n",
    "(scene, cont) = (1, 1) #Inicializamos el contador de escenas y de frames en buffer a 1\n",
    "(thr, buffsize) = (30, 30) #Especificamos el umbral y tamaño del buffer\n",
    "buffer = np.zeros((buffsize,h,w,c)) #Creación del buffer\n",
    "buffer[0] = frame   #Insertamos la primera frame\n",
    "\n",
    "writer = cv2.VideoWriter('video1_scene.mkv', cv2.VideoWriter_fourcc(*\"XVID\"),30, (w, h))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "        res = frame.copy()\n",
    "        if cont == buffsize:  #El buffer está lleno\n",
    "            \n",
    "            frame_ref = np.zeros((h,w,c), dtype='float32')\n",
    "            for item in buffer[:buffsize//2]:  #Tomamos la mitad inicial de frames y sacamos su frame promedio\n",
    "                frame_ref += item\n",
    "            frame_ref /= (buffsize/2)\n",
    "            \n",
    "            frame_act = np.zeros((h,w,c), dtype='float32')\n",
    "            for item in buffer[buffsize//2:]:  #Tomamos la mitad final de frames y sacamos su frame promedio\n",
    "                frame_act += item\n",
    "            frame_act /= (buffsize/2)\n",
    "            \n",
    "            img_diff = np.sum(cv2.absdiff(frame_ref, frame_act))/(w*h*3)   #Calculamos la diferencia media\n",
    "            \n",
    "            if (img_diff > thr): #Si supera el umbral, añadir 1 al condador de escenas y vaciar el buffer\n",
    "                scene = scene + 1\n",
    "                buffer = np.zeros((buffsize,h,w,c))\n",
    "                buffer[0] = frame  #Metemos la frame actual en el buffer vacio\n",
    "                cont = 1  #Inicializamos el contador de frames a 1\n",
    "            \n",
    "            else:  #Si no supera el umbral, quitamos el frame más antiguo en el buffer (primera posición) y añadimos el frame actual\n",
    "                buffer = np.delete(buffer, 0, 0)\n",
    "                buffer = np.append(buffer,res[np.newaxis,:,:,:],axis = 0)\n",
    "                \n",
    "        \n",
    "        else: #Si el buffer no está lleno, añadimos frames hasta que lo esté\n",
    "            buffer[cont] = frame\n",
    "            cont += 1\n",
    "    \n",
    "        \n",
    "        text = \"Scene \" + str(scene)  #Incluimos como texto el número de escena en el frame actual \n",
    "        cv2.putText(res, text, (150, 250), font, 1.5, white)\n",
    "        writer.write(res)\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "writer.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el video 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('video3.mkv')\n",
    "ret, frame = cap.read()\n",
    "(h, w, c) = frame.shape\n",
    "font = cv2.FONT_HERSHEY_TRIPLEX\n",
    "white = (255,255,255)\n",
    "(scene, cont) = (1, 1) #Inicializamos el contador de escenas y de frames en buffer a 1\n",
    "(thr, buffsize) = (30, 30)  #Especificamos el umbral y tamaño del buffer\n",
    "buffer = np.zeros((buffsize,h,w,c)) #Creación del buffer\n",
    "buffer[0] = frame  #Insertamos la primera frame\n",
    "\n",
    "writer = cv2.VideoWriter('video3_scene.mkv', cv2.VideoWriter_fourcc(*\"XVID\"),30, (w, h))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "        res = frame.copy()\n",
    "        if cont == buffsize: #El buffer está lleno\n",
    "            \n",
    "            frame_ref = np.zeros((h,w,c), dtype='float32')\n",
    "            for item in buffer[:buffsize//2]:  #Tomamos la mitad inicial de frames y sacamos su frame promedio\n",
    "                frame_ref += item\n",
    "            frame_ref /= (buffsize/2)\n",
    "            \n",
    "            frame_act = np.zeros((h,w,c), dtype='float32')  #Tomamos la mitad final de frames y sacamos su frame promedio\n",
    "            for item in buffer[buffsize//2:]:\n",
    "                frame_act += item\n",
    "            frame_act /= (buffsize/2)\n",
    "            \n",
    "            img_diff = np.sum(cv2.absdiff(frame_ref, frame_act))/(w*h*3)  #Calculamos la diferencia media\n",
    "            \n",
    "            if (img_diff > thr):  #Si supera el umbral, añadir 1 al condador de escenas y vaciar el buffer\n",
    "                scene = scene + 1\n",
    "                buffer = np.zeros((buffsize,h,w,c))\n",
    "                buffer[0] = frame  #Metemos la frame actual en el buffer vacio\n",
    "                cont = 1  #Inicializamos el contador de frames a 1\n",
    "            \n",
    "            else:  #Si no supera el umbral, quitamos el frame más antiguo en el buffer (primera posición) y añadimos el frame actual\n",
    "                buffer = np.delete(buffer, 0, 0)\n",
    "                buffer = np.append(buffer,res[np.newaxis,:,:,:],axis = 0)\n",
    "                \n",
    "        \n",
    "        else:  #Si el buffer no está lleno, añadimos frames hasta que lo esté\n",
    "            buffer[cont] = frame\n",
    "            cont += 1\n",
    "    \n",
    "        \n",
    "        text = \"Scene \" + str(scene)  #Incluimos como texto el número de escena en el frame actual \n",
    "        cv2.putText(res, text, (150, 250), font, 1.5, white)\n",
    "        writer.write(res)\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "writer.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3: Implementación de un segmentador foreground / background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el video 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('video2.mkv')\n",
    "ret, background_frame = cap.read() # Leemos el primer frame que será considerado el fondo\n",
    "(h, w, c) = background_frame.shape\n",
    "(thr,neig) = (80,1)    #Especificamos el umbral y vecindad\n",
    "writer = cv2.VideoWriter('video2_bgd_for.mkv', cv2.VideoWriter_fourcc(*\"XVID\"),30, (w, h))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "        res = cv2.absdiff(frame, background_frame) #Sacamos la diferencia entre el frame actual y el fondo\n",
    "        res = cv2.cvtColor(res, cv2.COLOR_BGR2GRAY) #Pasamos a escala de grises\n",
    "        res = np.array(res > thr, dtype='uint8') #Umbralizamos\n",
    "        \n",
    "        copy_res = res.copy() #Nos guardamos una copia del resultado\n",
    "        \n",
    "        #Filtramos el ruido \n",
    "        for i in range(neig,h-neig+1): \n",
    "            for j in range(neig,w-neig+1):\n",
    "                suma = np.sum(res[i-neig:i+neig+1, j-neig:j+neig+1]) #Sumamos por vecindad en la umbralización original\n",
    "                if suma <= 1: #Si es menor o igual que 1, fijamos a background en la copia\n",
    "                    copy_res[i,j] = 0\n",
    "        \n",
    "        \n",
    "        broad_res = np.broadcast_to(copy_res[:,:,np.newaxis], (h, w, c)) #Hacemos broadcast del resultado a 3 canales \n",
    "        res_final = broad_res * frame  #Multiplicamos por el frame original\n",
    "        writer.write(res_final)\n",
    "    \n",
    "    else:\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "writer.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el video 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('video4.mkv')\n",
    "ret, background_frame = cap.read() # Leemos el primer frame que será considerado el fondo\n",
    "(h, w, c) = background_frame.shape\n",
    "(thr,neig) = (80,1)    #Especificamos el umbral y vecindad\n",
    "writer = cv2.VideoWriter('video4_bgd_for.mkv', cv2.VideoWriter_fourcc(*\"XVID\"),30, (w, h))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "        res = cv2.absdiff(frame, background_frame)  #Sacamos la diferencia entre el frame actual y el fondo\n",
    "        res = cv2.cvtColor(res, cv2.COLOR_BGR2GRAY) #Pasamos a escala de grises\n",
    "        res = np.array(res > thr, dtype='uint8') #Umbralizamos\n",
    "        \n",
    "        copy_res = res.copy()  #Nos guardamos una copia del resultado\n",
    "        \n",
    "        #Filtramos el ruido \n",
    "        for i in range(neig,h-neig+1):\n",
    "            for j in range(neig,w-neig+1):\n",
    "                suma = np.sum(res[i-neig:i+neig+1, j-neig:j+neig+1])  #Sumamos por vecindad en la umbralización original\n",
    "                if suma <= 1:  #Si es menor o igual que 1, fijamos a background en la copia\n",
    "                    copy_res[i,j] = 0\n",
    "        \n",
    "        \n",
    "        broad_res = np.broadcast_to(copy_res[:,:,np.newaxis], (h, w, c)) #Hacemos broadcast del resultado a 3 canales \n",
    "        res_final = broad_res * frame  #Multiplicamos por el frame original\n",
    "        writer.write(res_final)\n",
    "    \n",
    "    else:\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
